<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>XSPLAIN: XAI-enabling Splat-based Prototype Learning</title>
    
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">

    <style>
        :root {
            --primary-color: #363636;
            --link-color: #3273dc;
            --bg-color: #ffffff;
            --light-bg: #f5f5f5;
        }

        body {
            font-family: 'Noto Sans', sans-serif;
            background-color: var(--bg-color);
            color: var(--primary-color);
            line-height: 1.6;
            margin: 0;
            padding: 0;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
        }

        h1, h2, h3 {
            font-family: 'Google Sans', sans-serif;
            text-align: center;
            font-weight: 500;
        }

        h1 { font-size: 2.5rem; margin-bottom: 10px; line-height: 1.2; }
        h2 { font-size: 1.75rem; margin-top: 40px; border-bottom: 2px solid #eee; padding-bottom: 10px; }
        h3 { font-size: 1.2rem; color: #555; }

        a { color: var(--link-color); text-decoration: none; }
        a:hover { text-decoration: underline; }

        .authors {
            text-align: center;
            font-size: 1.1rem;
            margin-top: 20px;
        }
        .affiliations {
            text-align: center;
            font-size: 0.9rem;
            color: #666;
            margin-top: 10px;
            margin-bottom: 20px;
        }
        .author-block { display: inline-block; margin-right: 10px; }
        .aff-block { display: block; }

        .link-buttons {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin: 30px 0;
        }
        .btn {
            background-color: #363636;
            color: white !important;
            padding: 10px 20px;
            border-radius: 30px;
            font-weight: bold;
            transition: opacity 0.3s;
            text-decoration: none !important;
            display: inline-flex;
            align-items: center;
            gap: 8px;
        }
        .btn:hover { opacity: 0.8; }
        .btn-dark { background-color: #1a1a1a; }

        .img-fluid {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        .caption {
            text-align: center;
            font-size: 0.9rem;
            color: #666;
            margin-top: -10px;
            margin-bottom: 20px;
            font-style: italic;
        }

        .abstract-box {
            background-color: var(--light-bg);
            padding: 30px;
            border-radius: 10px;
            margin-bottom: 30px;
            text-align: justify;
        }

        pre {
            background-color: #f4f4f4;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-size: 0.9rem;
            border: 1px solid #ddd;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 0.95rem;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: center;
        }
        th {
            background-color: #f8f9fa;
            font-weight: 600;
        }
        tr:nth-child(even) { background-color: #f9f9f9; }

        @media (max-width: 600px) {
            h1 { font-size: 1.8rem; }
            .btn { width: 100%; justify-content: center; }
            .link-buttons { flex-direction: column; gap: 10px; }
        }
    </style>
</head>
<body>

<div class="container">

    <h1>XSPLAIN: XAI-enabling Splat-based Prototype <br> Learning for Attribute-aware INterpretability</h1>

    <div class="authors">
        <span class="author-block">Dominik Galus<sup>1</sup>,</span>
        <span class="author-block">Julia Farganus<sup>1</sup>,</span>
        <span class="author-block">Tymoteusz Zapała<sup>1</sup>,</span>
        <span class="author-block">Mikołaj Czachorowski<sup>1</sup>,</span><br>
        <span class="author-block">Piotr Borycki<sup>2</sup>,</span>
        <span class="author-block">Przemysław Spurek<sup>2,3</sup>,</span>
        <span class="author-block">Piotr Syga<sup>1</sup></span>
    </div>

    <div class="affiliations">
        <span class="aff-block"><sup>1</sup> Wrocław University of Science and Technology</span>
        <span class="aff-block"><sup>2</sup> Jagiellonian University</span>
        <span class="aff-block"><sup>3</sup> IDEAS Research Institute</span>
    </div>

    <div class="link-buttons">
        <a href="https://arxiv.org/abs/2602.10239" class="btn btn-dark">
            <i class="fas fa-file-pdf"></i> Paper
        </a>
        <a href="https://github.com/Solvro/ml-splat-xai" class="btn btn-dark">
            <i class="fab fa-github"></i> Code
        </a>
    </div>

    <img src="resources/teaser.png" alt="XSPLAIN Teaser" class="img-fluid">
    <p class="caption">
        Figure 1. XSPLAIN provides ante-hoc, prototype-based explanations for 3D Gaussian Splat classification.
    </p>

    <div class="abstract-box">
        <h3>Abstract</h3>
        <p>
            3D Gaussian Splatting (3DGS) has rapidly become a standard for high-fidelity 3D reconstruction, yet its adoption in critical domains is hindered by the lack of interpretability. While explainability methods exist for point clouds, they typically rely on ambiguous saliency maps that fail to capture the volumetric coherence of Gaussian primitives. 
        </p>
        <p>
            We introduce <strong>XSPLAIN</strong>, the first ante-hoc, prototype-based interpretability framework designed specifically for 3DGS classification. Our approach leverages a voxel-aggregated PointNet backbone and a novel, invertible orthogonal transformation that disentangles feature channels for interpretability while strictly preserving decision boundaries. Explanations are grounded in representative training examples, enabling intuitive "this looks like that" reasoning without degradation in classification performance. A rigorous user study (N=51) demonstrates a decisive preference for our approach (p < 0.001) over existing post-hoc methods.
        </p>
    </div>

    <h2>Qualitative Results</h2>
    <p>
        XSPLAIN provides explanations by identifying coherent <strong>volumetric regions</strong> that drive the classification decision. Unlike traditional methods that rely on abstract saliency maps, our framework grounds its reasoning in geometry.
    </p>
    <p>
        The animation below demonstrates the <strong>"looks like that"</strong> reasoning process. For a given input object, XSPLAIN isolates specific disentangled attributes (e.g., engines, wings, or wheels) and retrieves the most similar prototypes from the training set that share these geometric features.
    </p>
    
    <div style="text-align: center; margin: 30px 0;">
        <img src="resources/microphone.gif" alt="XSPLAIN Method Animation" class="img-fluid" style="max-width: 800px;">
    </div>

    <p class="caption">
        Figure 3. Dynamic visualization of XSPLAIN. The model highlights specific parts of the query object (left) and matches them with semantically corresponding regions in training prototypes (right), validating the attribute-aware interpretability.
    </p>

    <h2>Methodology</h2>
    <p>
        XSPLAIN operates in two stages to decouple classification performance from interpretability:
    </p>
    <ul>
        <li><strong>Stage 1 (Backbone):</strong> A modified PointNet architecture with a Voxel Aggregation Module learns to classify 3DGS objects based on geometric attributes.</li>
        <li><strong>Stage 2 (Disentanglement):</strong> We freeze the backbone and train an invertible orthogonal transformation. This aligns the latent space so that specific feature channels correspond to semantic object parts (prototypes), enabling "looks like that" explanations.</li>
    </ul>
    
    <img src="resources/XSPLAIN-arch.png" alt="Architecture Diagram" class="img-fluid">
    <p class="caption">
        Figure 2. Overview of the XSPLAIN architecture: A) Classification Backbone, B) Disentangling Module, C) Prototype-based explaining.
    </p>

    <h3>User Study (N=51)</h3>
    <p>
        In a blinded A/B/C test against LIME and PointSHAP, participants significantly preferred XSPLAIN explanations.
    </p>
    <table>
        <thead>
            <tr>
                <th>Metric</th>
                <th>LIME</th>
                <th>PointSHAP</th>
                <th>XSPLAIN (Ours)</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>Preference (Best Method)</strong></td>
                <td>18%</td>
                <td>33%</td>
                <td><strong>49%</strong></td>
            </tr>
            <tr>
                <td><strong>High Confidence in Model</strong></td>
                <td>23%</td>
                <td>31%</td>
                <td><strong>46%</strong></td>
            </tr>
        </tbody>
    </table>

    <h2>Citation</h2>
    <pre><code>@misc{galus2026xsplain,
  title={XSPLAIN: XAI-enabling Splat-based Prototype Learning for Attribute-aware INterpretability},
  author={Dominik Galus and Julia Farganus and Tymoteusz Zapala and Mikołaj Czachorowski and Piotr Borycki and Przemysław Spurek and Piotr Syga},
  year={2026},
  eprint={2602.10239},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}</code></pre>

</div>

</body>
</html>
