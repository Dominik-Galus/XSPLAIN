<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>XSPLAIN</title>
<style>
body {
    font-family: Arial, Helvetica, sans-serif;
    max-width: 1000px;
    margin: auto;
    padding: 40px;
    line-height: 1.6;
}
h1, h2, h3 {
    text-align: center;
}
.center {
    text-align: center;
}
.links a {
    margin: 0 15px;
    text-decoration: none;
    font-weight: bold;
    font-size: 18px;
}
.section {
    margin-top: 60px;
}
pre {
    background: #f4f4f4;
    padding: 15px;
    overflow-x: auto;
}
code {
    background: #f4f4f4;
    padding: 3px 6px;
}
table {
    border-collapse: collapse;
    width: 100%;
}
th, td {
    border: 1px solid #ddd;
    padding: 8px;
    text-align: center;
}
th {
    background-color: #f2f2f2;
}
</style>
</head>

<body>

<h1>XSPLAIN</h1>
<h3>XAI-enabling Splat-based Prototype Learning for Attribute-aware INterpretability</h3>

<p class="center">
Dominik Galus Â· Julia Farganus Â· Tymoteusz ZapaÅ‚a Â· MikoÅ‚aj Czachorowski Â· 
Piotr Borycki Â· PrzemysÅ‚aw Spurek Â· Piotr Syga
</p>

<div class="center links">
    <a href="https://arxiv.org/abs/2602.10239">ðŸ“„ Paper</a>
    <a href="https://github.com/Solvro/ml-splat-xai">ðŸ’» Code</a>
</div>

<div class="section center">
    <em>Demo (loops):</em><br>
    <img src="resources/microphone.gif" width="920">
</div>

<div class="section center">
    <em>Teaser:</em><br>
    <img src="resources/teaser.png" width="920">
</div>

<div class="section">
<h2>Abstract</h2>
<p>
3D Gaussian Splatting (3DGS) has rapidly become a standard for high-fidelity 3D reconstruction, yet its adoption in multiple critical domains is hindered by the lack of interpretability of the generation models as well as classification of the Splats. While explainability methods exist for other 3D representations, like point clouds, they typically rely on ambiguous saliency maps that fail to capture the volumetric coherence of Gaussian primitives. We introduce XSPLAIN, the first ante-hoc, prototype-based interpretability framework designed specifically for 3DGS classification. Our approach leverages a voxel-aggregated PointNet backbone and a novel, invertible orthogonal transformation that disentangles feature channels for interpretability while strictly preserving the original decision boundaries. Explanations are grounded in representative training examples, enabling intuitive "this looks like that" reasoning without any degradation in classification performance. A rigorous user study (N=51) demonstrates a decisive preference for our approach (p < 0.001), showing that XSPLAIN provides transparency and user trust.
</p>
</div>

<div class="section center">
    <em>XSPLAIN Architecture:</em><br>
    <img src="resources/XSPLAIN-arch.png" width="920">
</div>

<div class="section">
<h2>Environment Setup</h2>
<p>Tested on Python >= 3.11</p>

<pre><code>python3 -m venv .venv
pip install -r requirements.txt</code></pre>
</div>

<div class="section">
<h2>Datasets</h2>
<ul>
<li><a href="https://arxiv.org/abs/2408.10906">ShapeSplat</a></li>
<li><a href="https://xiaobiaodu.github.io/3drealcar/">3DRealCar</a></li>
<li><a href="https://drive.google.com/drive/folders/19crk-rGoSAPTU8x58ELSNsqq6R9eTNEu?usp=sharing">TRELLIS Toys</a></li>
</ul>

<p>Expected structure:</p>

<pre><code>.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ test
â”‚   â”‚   â””â”€â”€ sample_001.ply
â”‚   â””â”€â”€ train
â”‚       â””â”€â”€ sample_001.ply
</code></pre>
</div>

<div class="section">
<h2>Training</h2>

<h3>Stage 1: Backbone</h3>
<pre><code>python3 train_stage_1_backbone.py --data_dir data --epochs 90</code></pre>

<h3>Stage 2: Disentangler</h3>
<pre><code>python3 train_stage_2_disentangler.py --pointnet_ckpt checkpoints/stage_1/pointnet_backbone.ckpt</code></pre>

<p>Or run both:</p>
<pre><code>python3 train_xsplain.py</code></pre>
</div>

<div class="section">
<h2>Explaining</h2>
<pre><code>python3 explain.py --ply_path path/to/input.ply --pointnet_ckpt checkpoints/stage_2/model.pt</code></pre>
</div>

<div class="section">
<h2>User Study Results</h2>

<p>
Participants (N=51) decisively preferred XSPLAIN explanations over SHAP and LIME.
</p>

<table>
<tr>
<th>Metric</th>
<th>LIME</th>
<th>SHAP</th>
<th>XSPLAIN (Ours)</th>
</tr>
<tr>
<td>Chosen as Best</td>
<td>17.95%</td>
<td>32.69%</td>
<td><strong>49.36%</strong></td>
</tr>
<tr>
<td>High Confidence</td>
<td>22.58%</td>
<td>30.97%</td>
<td><strong>46.45%</strong></td>
</tr>
<tr>
<td>Incorrect/Unsure</td>
<td>41.18%</td>
<td>32.35%</td>
<td><strong>26.47%</strong></td>
</tr>
</table>

</div>

<div class="section">
<h2>BibTeX</h2>

<pre><code>@misc{galus2026xsplainxaienablingsplatbasedprototype,
  title={XSPLAIN: XAI-enabling Splat-based Prototype Learning for Attribute-aware INterpretability},
  author={Dominik Galus and Julia Farganus and Tymoteusz Zapala and MikoÅ‚aj Czachorowski and Piotr Borycki and PrzemysÅ‚aw Spurek and Piotr Syga},
  year={2026},
  eprint={2602.10239},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2602.10239}
}
</code></pre>

</div>

</body>
</html>
